{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = loadmat(\"mnist_all.mat\")\n",
    "\n",
    "    # print(data.keys())\n",
    "\n",
    "    train_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "\n",
    "    for i in range(10):\n",
    "        temp_df = pd.DataFrame(data[\"train\" + str(i)])\n",
    "        temp_df['label'] = i\n",
    "        train_data = train_data.append(temp_df)\n",
    "        temp_df = pd.DataFrame(data[\"test\" + str(i)])\n",
    "        temp_df['label'] = i\n",
    "        test_data = test_data.append(temp_df)\n",
    "\n",
    "    train_data = shuffle(train_data)\n",
    "    test_data = shuffle(test_data)\n",
    "\n",
    "    train_labels = np.array(train_data['label'])\n",
    "    test_labels = np.array(test_data['label'])\n",
    "\n",
    "    train_data = train_data.drop('label', axis=1)\n",
    "    test_data = test_data.drop('label', axis=1)\n",
    "\n",
    "    train_data = np.array(train_data) / 255\n",
    "    test_data = np.array(test_data) / 255\n",
    "\n",
    "    return train_data, test_data, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.005\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "x_train, x_test, y_train, y_test = load_data()\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_DATASET(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.x[index].reshape(28, 28)), self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_ATTENTION(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, num_layers, num_classes):\n",
    "        super(LSTM_ATTENTION, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=in_dim, hidden_size=hidden_dim, num_layers=num_layers)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "\n",
    "        batch_size = value.shape[1]\n",
    "\n",
    "        # value (28, BATCH_SIZE, 256)\n",
    "\n",
    "        query = query[1, :, :].reshape(batch_size, 256, 1)  # query (BATCH_SIZE, 256, 1)\n",
    "\n",
    "        key = key.permute(1, 0, 2)  # key (BATCH_SIZE, 28, 256)\n",
    "\n",
    "        attention_weights = torch.bmm(key, query).reshape(batch_size, 28)  # attention_weights (BATCH_SZIE, 28)\n",
    "\n",
    "        softmax_attention_weights = F.softmax(attention_weights, dim=1).reshape(batch_size, 1, 28)\n",
    "        # softmax_attention_weights (BATCH_SIZE, 1, 28)\n",
    "\n",
    "        value = value.permute(1, 0, 2)  # value (BATCH_SIZE, 28, 256)\n",
    "\n",
    "        context = torch.bmm(softmax_attention_weights, value).reshape(batch_size, 256)\n",
    "\n",
    "        return context\n",
    "\n",
    "    def forward(self, x):\n",
    "        # hidden = (torch.randn(2, 256, 256).double(),\n",
    "        #           torch.randn(2, 256, 256).double())\n",
    "\n",
    "        out, (h, c) = self.lstm(x)\n",
    "\n",
    "        out = self.attention(h, out, out)\n",
    "\n",
    "        x = self.classifier(out)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    model = LSTM_ATTENTION(in_dim=28, hidden_dim=256, num_layers=2, num_classes=10)\n",
    "    model.to(DEVICE)\n",
    "    model.double()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    train_dataset = MNIST_DATASET(x_train, y_train)\n",
    "    valid_dataset = MNIST_DATASET(x_valid, y_valid)\n",
    "    test_dataset = MNIST_DATASET(x_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "\n",
    "    test_loader = DataLoader(dataset=test_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False)\n",
    "\n",
    "    valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "\n",
    "    best_model = None\n",
    "    best_acc = -1\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for index, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            images = torch.squeeze(images)\n",
    "            images = images.permute(1, 0, 2).double()\n",
    "\n",
    "            images = images.to(DEVICE)\n",
    "\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if index % 100 == 0:\n",
    "                print('Train Epoch [{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch + 1, EPOCHS, loss.item()))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_correct = 0\n",
    "            for images, labels in valid_loader:\n",
    "                images = torch.squeeze(images)\n",
    "                images = images.permute(1, 0, 2).double()\n",
    "\n",
    "                images = images.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                valid_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            acc = 100.0 * valid_correct / len(valid_loader.dataset)\n",
    "\n",
    "            print(\"Epoch: {} The accuracy of total {} images: {}%\".format(epoch + 1, len(valid_loader.dataset),\n",
    "                                                                          100.0 * valid_correct / len(\n",
    "                                                                              valid_loader.dataset)))\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "                print('get new model!')\n",
    "\n",
    "    model = copy.deepcopy(best_model)\n",
    "    model.to(DEVICE)\n",
    "    model.double()\n",
    "    with torch.no_grad():\n",
    "        test_correct = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = torch.squeeze(images)\n",
    "            images = images.permute(1, 0, 2).double()\n",
    "\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(\"The accuracy of total {} images: {}%\".format(len(test_loader.dataset),\n",
    "                                                        100.0 * test_correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [1/10], Loss: 2.3014\n",
      "Train Epoch [1/10], Loss: 0.3944\n",
      "Epoch: 1 The accuracy of total 12000 images: 95.59166666666667%\n",
      "get new model!\n",
      "Train Epoch [2/10], Loss: 0.2032\n",
      "Train Epoch [2/10], Loss: 0.0880\n",
      "Epoch: 2 The accuracy of total 12000 images: 97.35833333333333%\n",
      "get new model!\n",
      "Train Epoch [3/10], Loss: 0.0867\n",
      "Train Epoch [3/10], Loss: 0.1197\n",
      "Epoch: 3 The accuracy of total 12000 images: 97.94166666666666%\n",
      "get new model!\n",
      "Train Epoch [4/10], Loss: 0.0746\n",
      "Train Epoch [4/10], Loss: 0.1116\n",
      "Epoch: 4 The accuracy of total 12000 images: 98.21666666666667%\n",
      "get new model!\n",
      "Train Epoch [5/10], Loss: 0.0561\n",
      "Train Epoch [5/10], Loss: 0.0688\n",
      "Epoch: 5 The accuracy of total 12000 images: 98.625%\n",
      "get new model!\n",
      "Train Epoch [6/10], Loss: 0.0327\n",
      "Train Epoch [6/10], Loss: 0.0635\n",
      "Epoch: 6 The accuracy of total 12000 images: 98.6%\n",
      "Train Epoch [7/10], Loss: 0.0314\n",
      "Train Epoch [7/10], Loss: 0.0498\n",
      "Epoch: 7 The accuracy of total 12000 images: 98.68333333333334%\n",
      "get new model!\n",
      "Train Epoch [8/10], Loss: 0.0326\n",
      "Train Epoch [8/10], Loss: 0.0100\n",
      "Epoch: 8 The accuracy of total 12000 images: 98.90833333333333%\n",
      "get new model!\n",
      "Train Epoch [9/10], Loss: 0.0065\n",
      "Train Epoch [9/10], Loss: 0.0065\n",
      "Epoch: 9 The accuracy of total 12000 images: 98.875%\n",
      "Train Epoch [10/10], Loss: 0.0080\n",
      "Train Epoch [10/10], Loss: 0.0158\n",
      "Epoch: 10 The accuracy of total 12000 images: 98.73333333333333%\n",
      "The accuracy of total 10000 images: 98.83%\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
