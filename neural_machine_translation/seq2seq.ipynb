{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import spacy\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, \n",
    "                 n_layers, dropout=0.5, bidirectional=True):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.hid_dim = hid_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout,\n",
    "                           bidirectional=bidirectional)\n",
    "        \n",
    "    def forward(self, x, lens, hidden, cell):\n",
    "        \n",
    "        # x [seq_len, batch_size]\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, lens, enforce_sorted=False,\n",
    "                                                   batch_first=False)\n",
    "        \n",
    "        _, (hidden, cell) = self.rnn(packed, (hidden, cell))\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, \n",
    "                 n_layers, dropout=0.5, bidirectional=True):\n",
    "    \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout,\n",
    "                           bidirectional=bidirectional)\n",
    "        \n",
    "        if bidirectional:\n",
    "            self.fc = nn.Linear(hid_dim * 2, output_dim)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hid_dim, output_dim)\n",
    "            \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, hidden, cell):\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        x = x.reshape(1, -1)\n",
    "        # x [1, batch_size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        \n",
    "        output = output.reshape(batch_size, -1)\n",
    "        \n",
    "        output = F.log_softmax(self.fc(output), dim=1)\n",
    "        \n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, max_trg_len=100):\n",
    "        \n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        self.encoder.to(device)\n",
    "        self.decoder.to(device)\n",
    "        \n",
    "        self.n_encoder_directions = 2 if encoder.bidirectional else 1\n",
    "        \n",
    "        self.max_trg_len = max_trg_len\n",
    "        \n",
    "    def forward(self, src, src_lens, trg, trg_lens, teacher_forcing_ratio=0.5):\n",
    "        \n",
    "        # src [seq_len, batch_size]\n",
    "        # trg [seq_len, batch_size]\n",
    "        \n",
    "        batch_size = src.shape[1]\n",
    "        \n",
    "        hidden = torch.zeros(self.encoder.n_layers * self.n_encoder_directions, batch_size,\n",
    "                             self.encoder.hid_dim, device=self.device)\n",
    "        \n",
    "        cell = torch.zeros(self.encoder.n_layers * self.n_encoder_directions, batch_size,\n",
    "                           self.encoder.hid_dim, device=self.device)\n",
    "        \n",
    "        hidden, cell = self.encoder(src, src_lens, hidden, cell)\n",
    "        \n",
    "        x = trg[0, :]\n",
    "        \n",
    "        max_trg_len = max(trg_lens)\n",
    "        \n",
    "        outputs = torch.zeros(max_trg_len, batch_size, self.decoder.output_dim)\n",
    "        \n",
    "        for t in range(1, max_trg_len):\n",
    "            \n",
    "            output, hidden, cell = self.decoder(x.to(self.device), hidden, cell)\n",
    "            \n",
    "            outputs[t] = output\n",
    "            \n",
    "            top1 = output.argmax(dim=1).detach()\n",
    "            \n",
    "            teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            x = trg[t, :] if teacher_forcing else top1\n",
    "        \n",
    "        return outputs\n",
    "            \n",
    "    def translate(self, src, src_lens, trg):\n",
    "        \n",
    "        batch_size = src.shape[1]\n",
    "        \n",
    "        hidden = torch.zeros(self.encoder.n_layers * self.n_encoder_directions, batch_size,\n",
    "                             self.encoder.hid_dim, device=self.device)\n",
    "        \n",
    "        cell = torch.zeros(self.encoder.n_layers * self.n_encoder_directions, batch_size,\n",
    "                           self.encoder.hid_dim, device=self.device)\n",
    "        \n",
    "        hidden, cell = self.encoder(src, src_lens, hidden, cell)\n",
    "        \n",
    "        x = trg[0, :]\n",
    "        \n",
    "        outputs = torch.zeros(self.max_trg_len, batch_size, self.decoder.output_dim)\n",
    "        \n",
    "        for t in range(0, self.max_trg_len):\n",
    "            \n",
    "            output, hidden, cell = self.decoder(x.to(self.device), hidden, cell)\n",
    "            \n",
    "            outputs[t] = output\n",
    "            \n",
    "            top1 = output.argmax(dim=1).detach()\n",
    "            \n",
    "            x = top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, src, trg):\n",
    "        self.src = src\n",
    "        self.trg = trg\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'src': self.src[index]['sentence'],\n",
    "            'src_len': self.src[index]['len'],\n",
    "            'trg': self.trg[index]['sentence'],\n",
    "            'trg_len': self.trg[index]['len']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = spacy.load('en')\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings (tokens)\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  23610\n"
     ]
    }
   ],
   "source": [
    "with open('cmn.txt', 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "\n",
    "data = data.strip().split('\\n')\n",
    "\n",
    "print('number of examples: ', len(data))\n",
    "\n",
    "en_data = [line.split('\\t')[0] for line in data]\n",
    "zh_data = [line.split('\\t')[1] for line in data]\n",
    "\n",
    "assert len(en_data) == len(zh_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23610/23610 [00:02<00:00, 11239.16it/s]\n"
     ]
    }
   ],
   "source": [
    "zh_words = set()\n",
    "en_words = set()\n",
    "\n",
    "for i in tqdm(range(len(zh_data))):\n",
    "    en_seg = tokenize_en(en_data[i])\n",
    "    zh_seg = list(zh_data[i])\n",
    "\n",
    "    zh_words.update(zh_seg)\n",
    "    en_words.update(en_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_word2idx = {value: index + 4 for index, value in enumerate(zh_words)}\n",
    "\n",
    "zh_word2idx['<pad>'] = 0\n",
    "zh_word2idx['<sos>'] = 1\n",
    "zh_word2idx['<eos>'] = 2\n",
    "zh_word2idx['<unk>'] = 3\n",
    "\n",
    "zh_idx2word = {zh_word2idx[k]: k for k in zh_word2idx.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_word2idx = {value: index + 4 for index, value in enumerate(en_words)}\n",
    "\n",
    "en_word2idx['<pad>'] = 0\n",
    "en_word2idx['<sos>'] = 1\n",
    "en_word2idx['<eos>'] = 2\n",
    "en_word2idx['<unk>'] = 3\n",
    "\n",
    "en_idx2word = {en_word2idx[k]: k for k in en_word2idx.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23610/23610 [00:01<00:00, 15004.52it/s]\n"
     ]
    }
   ],
   "source": [
    "zh = []\n",
    "en = []\n",
    "\n",
    "for i in tqdm(range(len(zh_data))):\n",
    "    en_seg = tokenize_en(en_data[i])\n",
    "    zh_seg = list(zh_data[i])\n",
    "\n",
    "    en_sentence = [en_word2idx['<sos>']] + [en_word2idx[w] for w in en_seg] + [en_word2idx['<eos>']]\n",
    "    zh_sentence = [zh_word2idx['<sos>']] + [zh_word2idx[w] for w in zh_seg] + [zh_word2idx['<eos>']]\n",
    "\n",
    "    en_len = len(en_sentence)\n",
    "    zh_len = len(zh_sentence)\n",
    "\n",
    "    zh.append({\n",
    "         'sentence': zh_sentence,\n",
    "         'len': zh_len\n",
    "    })\n",
    "    en.append({\n",
    "        'sentence': en_sentence,\n",
    "        'len': en_len\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-4\n",
    "INPUT_DIM = len(en_word2idx)\n",
    "OUTPUT_DIM = len(zh_word2idx)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "HID_DIM = 512\n",
    "EMB_DIM = 256\n",
    "N_LAYERS = 2\n",
    "EPOCH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_batch(batch):\n",
    "\n",
    "    src_lens = [d[\"src_len\"] for d in batch]\n",
    "    trg_lens = [d[\"trg_len\"] for d in batch]\n",
    "\n",
    "    src_max = max([d[\"src_len\"] for d in batch])\n",
    "    trg_max = max([d[\"trg_len\"] for d in batch])\n",
    "\n",
    "    srcs = []\n",
    "    trgs = []\n",
    "\n",
    "    for d in batch:\n",
    "        src = copy.deepcopy(d['src'])\n",
    "        trg = copy.deepcopy(d['trg'])\n",
    "\n",
    "        src.extend([en_word2idx[\"<pad>\"]]*(src_max-d[\"src_len\"]))\n",
    "        trg.extend([zh_word2idx[\"<pad>\"]]*(trg_max-d[\"trg_len\"]))\n",
    "\n",
    "        srcs.append(src)\n",
    "        trgs.append(trg)\n",
    "\n",
    "    srcs = torch.tensor(srcs, dtype=torch.long, device=DEVICE)\n",
    "    trgs = torch.tensor(trgs, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    batch = {\"src\":srcs.T, \"src_lens\":src_lens,\n",
    "             \"trg\":trgs.T, \"trg_lens\":trg_lens}\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(INPUT_DIM, emb_dim=EMB_DIM, hid_dim=HID_DIM, n_layers=N_LAYERS)\n",
    "decoder = Decoder(OUTPUT_DIM, emb_dim=EMB_DIM, hid_dim=HID_DIM, n_layers=N_LAYERS)\n",
    "model = Seq2Seq(encoder, decoder, DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.NLLLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NMTDataset(en, zh)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn=padding_batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss = sys.maxsize\n",
    "print_every = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    print_loss_total = 0\n",
    "    \n",
    "    model.train()\n",
    "    for index, batch in enumerate(dataloader):\n",
    "        \n",
    "        src = batch['src']\n",
    "        src_lens = batch['src_lens']\n",
    "        trg = batch['trg']\n",
    "        trg_lens = batch['trg_lens']\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(src, src_lens, trg, trg_lens)\n",
    "        \n",
    "        outputs = outputs[1:, :, :]\n",
    "        \n",
    "        outputs = outputs.reshape(-1, OUTPUT_DIM)\n",
    "        \n",
    "        trg = trg[1:, :]\n",
    "        \n",
    "        trg = trg.reshape(-1).cpu()\n",
    "        \n",
    "        loss = criterion(outputs, trg)\n",
    "        \n",
    "        print_loss_total += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (index + 1) % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            \n",
    "            info = 'Train Epoch [{}/{}], Avg Loss: {:.4f}'. \\\n",
    "                    format(epoch + 1, EPOCH, print_loss_avg)\n",
    "            print(info)\n",
    "    \n",
    "    valid_loss = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(dataloader):\n",
    "            \n",
    "            src = batch['src']\n",
    "            src_lens = batch['src_lens']\n",
    "            trg = batch['trg']\n",
    "            trg_lens = batch['trg_lens']\n",
    "            \n",
    "            output = model(src, src_lens, trg, trg_lens, teacher_forcing_ratio=0)\n",
    "            \n",
    "            outputs = model(src, src_lens, trg, trg_lens)\n",
    "        \n",
    "            outputs = outputs[1:, :, :]\n",
    "\n",
    "            outputs = outputs.reshape(-1, OUTPUT_DIM)\n",
    "\n",
    "            trg = trg[1:, :]\n",
    "\n",
    "            trg = trg.reshape(-1).cpu()\n",
    "\n",
    "            loss = criterion(outputs, trg)\n",
    "            \n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    valid_loss = valid_loss / len(dataloader)\n",
    "    info = 'Train Epoch [{}/{}], Valid Loss: {:.4f}'. \\\n",
    "            format(epoch + 1, EPOCH, valid_loss)\n",
    "    print(info)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'seq2seq.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best valid loss: 0.036710509526971226\n"
     ]
    }
   ],
   "source": [
    "print('best valid loss: {}'.format(best_valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('seq2seq.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, en):\n",
    "    en = tokenize_en(en)\n",
    "    en.append('<eos>')\n",
    "    \n",
    "    en_len = len(en)\n",
    "\n",
    "    en_data = []\n",
    "\n",
    "    for w in en:\n",
    "        if w in en_word2idx.keys():\n",
    "            en_data.append(en_word2idx[w])\n",
    "        else:\n",
    "            en_data.append(en_word2idx['<unk>'])\n",
    "    en = en_data\n",
    "    \n",
    "    en = [en]\n",
    "\n",
    "    en = torch.LongTensor(en).permute(1, 0)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.translate(en.to(DEVICE), [en_len], torch.LongTensor([[1]]))\n",
    "\n",
    "        outputs = outputs.permute(1, 0, 2).cpu().detach().numpy()\n",
    "\n",
    "        outputs = np.argmax(outputs, axis=2)\n",
    "\n",
    "        outputs = outputs[0]\n",
    "\n",
    "        zh_data = []\n",
    "\n",
    "        for w in outputs:\n",
    "            if w in zh_idx2word.keys():\n",
    "                zh_data.append(zh_idx2word[w])\n",
    "                if zh_idx2word[w] == '<eos>':\n",
    "                    break\n",
    "            else:\n",
    "                zh_data.append('<unk>')\n",
    "\n",
    "        print(zh_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['他', '有', '危', '險', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "# 他們有危險。\n",
    "translate(model, 'They are in danger.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '爱', '您', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "translate(model, 'I love you.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '們', '問', '問', '湯', '姆', '看', '看', '他', '他', '什', '麼', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "# 我們要問問湯姆，看看他怎麼想。\n",
    "translate(model, 'We\\'ll ask Tom and see what he thinks.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['他', '受', '不', '了', '咖', '啡', '的', '苦', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "# 他受不了咖啡的苦味。\n",
    "translate(model, 'He couldn\\'t stand the bitterness of the coffee.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['他', '扔', '一', '塊', '石', '塘', '到', '池', '塘', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "# 他扔一塊石頭到池塘裡。\n",
    "translate(model, 'He threw a stone into the pond.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '喜', '歡', '面', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "translate(model, 'I like eating bread.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一', '週', '之', '內', '就', '回', '家', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "# 她一週之內會回來。\n",
    "translate(model, 'She will be back within a week.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
